{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SCRIPT: Extract_ViT_Features_With_Path_and_Labels.py\n",
    "# DESCRIPTION: This script extracts Vision Transformer (ViT) features from images \n",
    "#              in a dataset organized by hospital classes (C_0 to C_4) with subfolders\n",
    "#              (L_0 or L_1). It saves feature vectors along with full file paths, \n",
    "#              dataset labels (C_0 to C_4), and inner labels (L_0 or L_1) in .pkl files\n",
    "#              for each hospital. The script uses a pretrained ViT model from Hugging Face.\n",
    "# AUTHOR: Amir Soleimani-Yazdi\n",
    "# DATE: 2025-09-19\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Imports ---\n",
    "# ------------------------------------------------------------------------------\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Other imports for potential downstream analysis (kept for compatibility)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# --- 2. Load Pretrained ViT Model and Image Processor ---\n",
    "# ------------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Hugging Face model name\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "# Load the ViT model and its corresponding image processor\n",
    "model = ViTModel.from_pretrained(model_name).to(device)\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)\n",
    "model.eval()\n",
    "print(f\"‚úÖ ViT model '{model_name}' loaded on {device}.\")\n",
    "\n",
    "# --- 3. Feature Extraction Function for ViT ---\n",
    "# ------------------------------------------------------------------------------\n",
    "def extract_features_vit(image_paths, model, processor, hospital_id):\n",
    "    features = []\n",
    "    for path in tqdm(image_paths, desc=f\"Extracting ViT features for {hospital_id}\"):\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            \n",
    "            # Use the ViT image processor\n",
    "            inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Get the model's output\n",
    "                outputs = model(**inputs)\n",
    "                \n",
    "                # Use the .pooler_output for the [CLS] token representation (shape: 768,)\n",
    "                feature = outputs.pooler_output.squeeze().cpu().numpy()\n",
    "                \n",
    "                # Extract inner label (L_0 or L_1) from the path\n",
    "                inner_label = 'L_0' if 'L_0' in path else 'L_1' if 'L_1' in path else 'Unknown'\n",
    "                \n",
    "                # Store tuple: (full_path, feature_vector, dataset_label, inner_label)\n",
    "                features.append((path, feature, hospital_id, inner_label))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with {path}: {e}\")\n",
    "    return features\n",
    "\n",
    "# --- 4. Extract and Save Features for Each Hospital ---\n",
    "# ------------------------------------------------------------------------------\n",
    "dataset_dir = r\"d:\\new_patches\\new_patches\"\n",
    "hospital_features = {}\n",
    "\n",
    "# Define output directory for .pkl files (same as t-SNE script for compatibility)\n",
    "output_dir = r\"d:\\.kaggle\\new_FE_ViT_with_Path_and_Labels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(5):\n",
    "    hospital_id = f\"C_{i}\"\n",
    "    hospital_path = os.path.join(dataset_dir, hospital_id)\n",
    "\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(hospital_path):\n",
    "        image_paths += [os.path.join(root, f) for f in files if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    print(f\"\\n‚û°Ô∏è {hospital_id} - Total Images: {len(image_paths)}\")\n",
    "\n",
    "    if image_paths:\n",
    "        # Call the feature extraction function with hospital_id\n",
    "        feature_vectors = extract_features_vit(image_paths, model, image_processor, hospital_id)\n",
    "        \n",
    "        # Save to .pkl file in the output directory\n",
    "        output_filename = os.path.join(output_dir, f\"features_vit_{hospital_id}.pkl\")\n",
    "        with open(output_filename, \"wb\") as f:\n",
    "            pickle.dump(feature_vectors, f)\n",
    "            \n",
    "        hospital_features[hospital_id] = feature_vectors\n",
    "        print(f\"üíæ Saved {output_filename}\")\n",
    "\n",
    "print(\"\\n--- Feature Extraction Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looading and preparing latent vectors and Tsne coordinations \n",
    "\n",
    "# ==============================================================================\n",
    "# SCRIPT: ViT_Feature_tSNE_Analysis_Full_C2_Distances.py\n",
    "# DESCRIPTION: This script performs t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "#              on the full set of Vision Transformer (ViT) feature vectors from all classes\n",
    "#              (C_0 to C_4). It generates an Excel file with filename, path, t-SNE coordinates,\n",
    "#              dataset (C_0 to C_4), inner label (L_0 or L_1), and distances to all centroids\n",
    "#              for all samples. A separate Excel file is generated for C_2 samples' distances\n",
    "#              to centroids. Visualizations (scatter plot, heatmaps) use subsampled points for\n",
    "#              efficiency. Outputs are saved in a new folder for full t-SNE results.\n",
    "# AUTHOR:\n",
    "# DATE: 2025-09-19\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Import Necessary Libraries ---\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform, cosine, cdist\n",
    "\n",
    "# --- 2. Configuration and Setup ---\n",
    "# ------------------------------------------------------------------------------\n",
    "# Define the base directory where feature files are located.\n",
    "FEATURE_DIR = r\"d:\\.kaggle\"\n",
    "\n",
    "# Define the directory where all outputs (plots, data files) will be saved.\n",
    "OUTPUT_DIR = r\"d:\\.kaggle\\outputs_newRR5_vit_tsne_full09192025\"\n",
    "\n",
    "# Create the output directory if it doesn't already exist.\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Subsampling configuration (for visualization only)\n",
    "SUBSAMPLE_SIZE = 1000  # Maximum total samples for visualization\n",
    "SUBSAMPLE_FRACTION = 0.1  # Fraction per class for visualization\n",
    "\n",
    "print(\"--- Configuration Complete ---\")\n",
    "print(f\"Feature source directory: {FEATURE_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "# --- 3. Data Loading and Preprocessing ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"--- Step 1: Loading and Preparing Data ---\")\n",
    "\n",
    "# A dictionary to hold the feature vectors and filenames for each class/hospital.\n",
    "all_features = {}\n",
    "all_filenames = {}\n",
    "\n",
    "# Initialize empty lists to aggregate data from all files.\n",
    "labels = []\n",
    "feature_vectors = []\n",
    "filenames = []\n",
    "\n",
    "# Loop through the 5 classes (C_0 to C_4).\n",
    "for i in range(5):\n",
    "    hospital_id = f\"C_{i}\"\n",
    "    \n",
    "    # Construct the full path to the feature file.\n",
    "    feature_file_path = os.path.join(FEATURE_DIR, f\"features_vit_{hospital_id}.pkl\")\n",
    "\n",
    "    # Check if the file exists before trying to open it.\n",
    "    if os.path.exists(feature_file_path):\n",
    "        print(f\"--> Loading features for {hospital_id} from {feature_file_path}...\")\n",
    "        try:\n",
    "            with open(feature_file_path, \"rb\") as f:\n",
    "                # Load the data from the pickle file.\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Extract the feature vectors and filenames.\n",
    "                class_features = [item[1] for item in data]\n",
    "                class_filenames = [item[0] for item in data]\n",
    "                \n",
    "                # Store the loaded features and filenames.\n",
    "                all_features[hospital_id] = class_features\n",
    "                all_filenames[hospital_id] = class_filenames\n",
    "                \n",
    "                # Append features, filenames, and corresponding labels to master lists.\n",
    "                feature_vectors.extend(class_features)\n",
    "                filenames.extend(class_filenames)\n",
    "                labels.extend([hospital_id] * len(class_features))\n",
    "                \n",
    "                print(f\"    ‚úÖ Loaded {len(class_features)} feature vectors for {hospital_id}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è Error loading {feature_file_path}: {e}. Skipping.\")\n",
    "    else:\n",
    "        print(f\"    ‚ö†Ô∏è File not found for {hospital_id} at {feature_file_path}. Skipping.\")\n",
    "\n",
    "# Convert to NumPy arrays.\n",
    "if not feature_vectors:\n",
    "    print(\"\\nError: No feature files were found. Exiting script.\")\n",
    "    exit()\n",
    "\n",
    "feature_vectors = np.array(feature_vectors)\n",
    "labels = np.array(labels)\n",
    "filenames = np.array(filenames)\n",
    "print(f\"\\nSuccessfully combined all features.\")\n",
    "print(f\"Shape of the combined data matrix: {feature_vectors.shape}\")\n",
    "\n",
    "# --- 4. Data Standardization ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 2: Standardizing Data ---\")\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(feature_vectors)\n",
    "print(\"‚úÖ Full data has been standardized (zero mean, unit variance).\\n\")\n",
    "\n",
    "# --- 5. t-SNE Analysis on Full Data ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"--- Step 3: Applying t-SNE to Full Dataset ---\")\n",
    "\n",
    "# Adjust perplexity based on full dataset size (must be less than number of samples).\n",
    "n_samples = len(feature_vectors)\n",
    "perplexity = min(30, max(5, n_samples // 3))  # Dynamic perplexity\n",
    "print(f\"Using perplexity={perplexity} for full t-SNE (adjusted for {n_samples} samples).\")\n",
    "\n",
    "# Initialize t-SNE with 2 components for 2D visualization.\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, init='pca', n_jobs=-1)\n",
    "tsne_result = tsne.fit_transform(standardized_data)\n",
    "\n",
    "print(\"‚úÖ t-SNE fitting and transformation complete.\")\n",
    "print(f\"Shape of data after t-SNE: {tsne_result.shape}\")\n",
    "print(f\"KL divergence (cost function): {tsne.kl_divergence_:.4f}\")\n",
    "\n",
    "# --- 6. Subsampling for Visualization ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 4: Stratified Subsampling for Visualization ---\")\n",
    "sub_indices = []\n",
    "num_classes = 5  # Assuming 5 classes (C_0 to C_4)\n",
    "subsample_size_per_class = max(1, SUBSAMPLE_SIZE // num_classes)\n",
    "unique_labels = sorted(set(labels))\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = np.where(labels == label)[0]\n",
    "    n_label = len(label_indices)\n",
    "    n_sub_label = min(n_label, max(subsample_size_per_class, int(n_label * SUBSAMPLE_FRACTION)))\n",
    "    if n_label > 0:\n",
    "        sub_label_idx = np.random.choice(label_indices, size=n_sub_label, replace=False)\n",
    "        sub_indices.extend(sub_label_idx)\n",
    "\n",
    "sub_indices = np.array(sub_indices)\n",
    "sub_tsne_result = tsne_result[sub_indices]\n",
    "sub_labels = labels[sub_indices]\n",
    "sub_filenames = filenames[sub_indices]\n",
    "print(f\"    ‚úÖ Subsampled {len(sub_indices)} points for visualization.\")\n",
    "print(f\"    Subsampled t-SNE shape: {sub_tsne_result.shape}\")\n",
    "\n",
    "# --- 7. Calculate Centroids, Euclidean Distances, and Cosine Similarities ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 5: Calculating Centroids, Euclidean Distances, and Cosine Similarities ---\")\n",
    "\n",
    "# Calculate centroids for each class in t-SNE space (using subsampled data for visualization).\n",
    "centroids = {}\n",
    "for label in unique_labels:\n",
    "    indices = np.where(sub_labels == label)[0]\n",
    "    centroid = np.mean(sub_tsne_result[indices], axis=0)\n",
    "    centroids[label] = centroid\n",
    "    print(f\"Centroid for {label}: {centroid}\")\n",
    "\n",
    "# Compute pairwise Euclidean distances between centroids.\n",
    "centroid_coords = np.array([centroids[label] for label in unique_labels])\n",
    "euclidean_distances = squareform(pdist(centroid_coords, metric='euclidean'))\n",
    "euclidean_distance_df = pd.DataFrame(euclidean_distances, index=unique_labels, columns=unique_labels)\n",
    "print(\"\\nPairwise Euclidean distances between centroids:\")\n",
    "print(euclidean_distance_df)\n",
    "\n",
    "# Save the Euclidean distance matrix to a CSV file.\n",
    "euclidean_distance_output_path = os.path.join(OUTPUT_DIR, 'centroid_euclidean_distances.csv')\n",
    "euclidean_distance_df.to_csv(euclidean_distance_output_path)\n",
    "print(f\"‚úÖ Euclidean centroid distances saved to: {euclidean_distance_output_path}\")\n",
    "\n",
    "# Compute pairwise cosine similarities between centroids.\n",
    "cosine_similarities = np.zeros((len(unique_labels), len(unique_labels)))\n",
    "for i, label1 in enumerate(unique_labels):\n",
    "    for j, label2 in enumerate(unique_labels):\n",
    "        if i == j:\n",
    "            cosine_similarities[i, j] = 1.0\n",
    "        else:\n",
    "            cosine_similarities[i, j] = 1 - cosine(centroid_coords[i], centroid_coords[j])\n",
    "\n",
    "cosine_similarity_df = pd.DataFrame(cosine_similarities, index=unique_labels, columns=unique_labels)\n",
    "print(\"\\nPairwise Cosine similarities between centroids:\")\n",
    "print(cosine_similarity_df)\n",
    "\n",
    "# Save the cosine similarity matrix to a CSV file.\n",
    "cosine_similarity_output_path = os.path.join(OUTPUT_DIR, 'centroid_cosine_similarities.csv')\n",
    "cosine_similarity_df.to_csv(cosine_similarity_output_path)\n",
    "print(f\"‚úÖ Cosine similarities saved to: {cosine_similarity_output_path}\")\n",
    "\n",
    "# --- 8. Generate Excel File with Full t-SNE Results ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 6: Generating Excel File with Full t-SNE Results ---\")\n",
    "\n",
    "# Create a DataFrame for all samples' t-SNE coordinates and metadata.\n",
    "excel_data_full = {\n",
    "    'Filename': [],\n",
    "    'Path': [],\n",
    "    'tSNE_X': [],\n",
    "    'tSNE_Y': [],\n",
    "    'Dataset': [],\n",
    "    'Inner_Label': [],\n",
    "    'Dist_to_C_0': [],\n",
    "    'Dist_to_C_1': [],\n",
    "    'Dist_to_C_2': [],\n",
    "    'Dist_to_C_3': [],\n",
    "    'Dist_to_C_4': []\n",
    "}\n",
    "\n",
    "# Use vectorized distance calculation for all samples to centroids.\n",
    "all_distances = cdist(tsne_result, centroid_coords, metric='euclidean')\n",
    "\n",
    "for idx in range(len(filenames)):\n",
    "    # Extract filename and path.\n",
    "    file_path = filenames[idx]\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract inner label (L_0 or L_1) from the path.\n",
    "    inner_label = 'L_0' if 'L_0' in file_path else 'L_1' if 'L_1' in file_path else 'Unknown'\n",
    "    \n",
    "    excel_data_full['Filename'].append(file_name)\n",
    "    excel_data_full['Path'].append(file_path)\n",
    "    excel_data_full['tSNE_X'].append(tsne_result[idx, 0])\n",
    "    excel_data_full['tSNE_Y'].append(tsne_result[idx, 1])\n",
    "    excel_data_full['Dataset'].append(labels[idx])\n",
    "    excel_data_full['Inner_Label'].append(inner_label)\n",
    "    \n",
    "    # Assign distances to each centroid.\n",
    "    for j, target_label in enumerate(unique_labels):\n",
    "        excel_data_full[f'Dist_to_{target_label}'].append(all_distances[idx, j])\n",
    "\n",
    "# Convert to DataFrame and save to Excel.\n",
    "excel_df_full = pd.DataFrame(excel_data_full)\n",
    "excel_full_output_path = os.path.join(OUTPUT_DIR, 'all_data_with_tsne_and_centroid_distances.xlsx')\n",
    "excel_df_full.to_excel(excel_full_output_path, index=False, engine='openpyxl')\n",
    "print(f\"‚úÖ Excel file with full t-SNE results saved to: {excel_full_output_path}\")\n",
    "\n",
    "# --- 9. Generate Excel File with C_2 Sample Distances (Separate t-SNE) ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 7: Generating Excel File with C_2 Sample Distances ---\")\n",
    "\n",
    "# Perform t-SNE on full C_2 data to get coordinates for distance calculations.\n",
    "c2_indices_full = np.where(labels == 'C_2')[0]\n",
    "if len(c2_indices_full) == 0:\n",
    "    print(\"\\nWarning: No C_2 samples found in the data. Skipping C_2 Excel output.\")\n",
    "else:\n",
    "    print(f\"--> Performing t-SNE on {len(c2_indices_full)} C_2 samples for distance calculations...\")\n",
    "    c2_features = feature_vectors[c2_indices_full]\n",
    "    c2_standardized = scaler.fit_transform(c2_features)\n",
    "    \n",
    "    # Adjust perplexity for C_2 samples.\n",
    "    c2_perplexity = min(30, max(5, len(c2_indices_full) // 3))\n",
    "    print(f\"Using perplexity={c2_perplexity} for C_2 t-SNE.\")\n",
    "    \n",
    "    c2_tsne = TSNE(n_components=2, perplexity=c2_perplexity, random_state=42, init='pca', n_jobs=-1)\n",
    "    c2_tsne_result = c2_tsne.fit_transform(c2_standardized)\n",
    "    print(f\"‚úÖ C_2 t-SNE complete. Shape: {c2_tsne_result.shape}\")\n",
    "\n",
    "    # Create a DataFrame for the C_2 Excel file with distances to all centroids.\n",
    "    excel_data_c2 = {\n",
    "        'Filename': [],\n",
    "        'Path': [],\n",
    "        'tSNE_X': [],\n",
    "        'tSNE_Y': [],\n",
    "        'Dataset': [],\n",
    "        'Inner_Label': [],\n",
    "        'Dist_to_C_0': [],\n",
    "        'Dist_to_C_1': [],\n",
    "        'Dist_to_C_2': [],\n",
    "        'Dist_to_C_3': [],\n",
    "        'Dist_to_C_4': []\n",
    "    }\n",
    "\n",
    "    # Use vectorized distance calculation.\n",
    "    c2_distances = cdist(c2_tsne_result, centroid_coords, metric='euclidean')\n",
    "    \n",
    "    for idx, orig_idx in enumerate(c2_indices_full):\n",
    "        file_path = filenames[orig_idx]\n",
    "        file_name = os.path.basename(file_path)\n",
    "        inner_label = 'L_0' if 'L_0' in file_path else 'L_1' if 'L_1' in file_path else 'Unknown'\n",
    "        \n",
    "        excel_data_c2['Filename'].append(file_name)\n",
    "        excel_data_c2['Path'].append(file_path)\n",
    "        excel_data_c2['tSNE_X'].append(c2_tsne_result[idx, 0])\n",
    "        excel_data_c2['tSNE_Y'].append(c2_tsne_result[idx, 1])\n",
    "        excel_data_c2['Dataset'].append('C_2')\n",
    "        excel_data_c2['Inner_Label'].append(inner_label)\n",
    "        \n",
    "        # Assign distances to each centroid.\n",
    "        for j, target_label in enumerate(unique_labels):\n",
    "            excel_data_c2[f'Dist_to_{target_label}'].append(c2_distances[idx, j])\n",
    "\n",
    "    # Convert to DataFrame and save to Excel.\n",
    "    excel_df_c2 = pd.DataFrame(excel_data_c2)\n",
    "    excel_c2_output_path = os.path.join(OUTPUT_DIR, 'C2_data_with_all_centroids_ViT_tSNE.xlsx')\n",
    "    excel_df_c2.to_excel(excel_c2_output_path, index=False, engine='openpyxl')\n",
    "    print(f\"‚úÖ Excel file with C_2 sample distances saved to: {excel_c2_output_path}\")\n",
    "\n",
    "# --- 10. Visualization ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 8: Visualizing t-SNE Results and Centroid Metrics ---\")\n",
    "\n",
    "# Scatter plot of t-SNE results with centroids (using subsampled points).\n",
    "try:\n",
    "    plt.style.use('ggplot')\n",
    "except OSError:\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    plt.rcParams['grid.linewidth'] = 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Plot subsampled t-SNE points.\n",
    "palette = sns.color_palette(\"deep\", n_colors=len(unique_labels))\n",
    "color_map = dict(zip(unique_labels, palette))\n",
    "for label, color in color_map.items():\n",
    "    sub_label_mask = (sub_labels == label)\n",
    "    ax.scatter(\n",
    "        sub_tsne_result[sub_label_mask, 0],\n",
    "        sub_tsne_result[sub_label_mask, 1],\n",
    "        label=label,\n",
    "        color=color,\n",
    "        alpha=0.6,\n",
    "        s=15\n",
    "    )\n",
    "\n",
    "# Plot centroids (from subsampled data).\n",
    "for label, centroid in centroids.items():\n",
    "    ax.scatter(\n",
    "        centroid[0], centroid[1],\n",
    "        color=color_map[label],\n",
    "        marker='*',\n",
    "        s=200,\n",
    "        edgecolors='black',\n",
    "        label=f'{label} Centroid'\n",
    "    )\n",
    "\n",
    "ax.set_title('2D t-SNE of ViT Feature Embeddings by Class with Centroids (Subsampled Points)', fontsize=18, fontweight='bold')\n",
    "ax.set_xlabel('tSNE_X', fontsize=12)\n",
    "ax.set_ylabel('tSNE_Y', fontsize=12)\n",
    "ax.legend(title='Class ID', fontsize=10)\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "tsne_plot_path = os.path.join(OUTPUT_DIR, 'tsne_visualization_with_centroids.png')\n",
    "plt.savefig(tsne_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ t-SNE visualization saved to: {tsne_plot_path}\")\n",
    "\n",
    "# Heatmap of Euclidean distances.\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(euclidean_distance_df, annot=True, cmap='viridis', fmt='.2f', cbar_kws={'label': 'Euclidean Distance'})\n",
    "plt.title('Pairwise Euclidean Distances Between Class Centroids in t-SNE Space', fontsize=16)\n",
    "plt.xlabel('Class ID', fontsize=12)\n",
    "plt.ylabel('Class ID', fontsize=12)\n",
    "\n",
    "euclidean_heatmap_path = os.path.join(OUTPUT_DIR, 'centroid_euclidean_distances_heatmap.png')\n",
    "plt.savefig(euclidean_heatmap_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Euclidean distances heatmap saved to: {euclidean_heatmap_path}\")\n",
    "\n",
    "# Heatmap of cosine similarities.\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cosine_similarity_df, annot=True, cmap='viridis', fmt='.2f', cbar_kws={'label': 'Cosine Similarity'})\n",
    "plt.title('Pairwise Cosine Similarities Between Class Centroids in t-SNE Space', fontsize=16)\n",
    "plt.xlabel('Class ID', fontsize=12)\n",
    "plt.ylabel('Class ID', fontsize=12)\n",
    "\n",
    "cosine_heatmap_path = os.path.join(OUTPUT_DIR, 'centroid_cosine_similarities_heatmap.png')\n",
    "plt.savefig(cosine_heatmap_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Cosine similarities heatmap saved to: {cosine_heatmap_path}\")\n",
    "\n",
    "# Close all figures to free memory.\n",
    "plt.close('all')\n",
    "\n",
    "# --- 11. Save Processed Data for Future Use ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 9: Saving t-SNE Results and Labels ---\")\n",
    "\n",
    "tsne_output_path = os.path.join(OUTPUT_DIR, 'tsne_result_full.npy')\n",
    "np.save(tsne_output_path, tsne_result)\n",
    "print(f\"‚úÖ Full t-SNE transformed data saved to: {tsne_output_path}\")\n",
    "\n",
    "labels_output_path = os.path.join(OUTPUT_DIR, 'labels_full.npy')\n",
    "np.save(labels_output_path, labels)\n",
    "print(f\"‚úÖ Full labels saved to: {labels_output_path}\")\n",
    "\n",
    "print(\"\\n--- Script Finished Successfully ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build TSNE dataset \n",
    "\n",
    "# ==============================================================================\n",
    "# SCRIPT: ViT_Feature_tSNE_Analysis_Full_C0_to_C5_NoCentroids.py\n",
    "# DESCRIPTION: This script performs t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "#              on the full set of Vision Transformer (ViT) feature vectors from all classes\n",
    "#              (C_0 to C_5, 378,354 + C_5 samples) without subsampling. It generates an Excel\n",
    "#              file with filename, full file path, t-SNE coordinates, dataset (C_0 to C_5),\n",
    "#              and inner label (L_0 or L_1) for all samples. A scatter plot visualizes\n",
    "#              subsampled points (1,000 total). Outputs are saved in a new folder. Compatible\n",
    "#              with .pkl files containing (full_path, feature, dataset_label, inner_label)\n",
    "#              tuples. Uses float16 to reduce memory usage and skips centroid distance\n",
    "#              calculations to avoid MemoryError.\n",
    "# AUTHOR:\n",
    "# DATE: 2025-10-01\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Import Necessary Libraries ---\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# --- 2. Configuration and Setup ---\n",
    "# ------------------------------------------------------------------------------\n",
    "# Define the base directory where feature files are located.\n",
    "FEATURE_DIR = r\"d:\\.kaggle\\new_FE_ViT_with_Path_and_Labels\"\n",
    "\n",
    "# Define the directory where all outputs (plots, data files) will be saved.\n",
    "OUTPUT_DIR = r\"d:\\.kaggle\\outputs_newRR5_vit_tsne_full\"\n",
    "\n",
    "# Create the output directory if it doesn't already exist.\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Subsampling configuration for visualization only\n",
    "SUBSAMPLE_SIZE = 1000  # Maximum total samples for visualization\n",
    "SUBSAMPLE_FRACTION = 0.1  # Fraction per class for visualization\n",
    "\n",
    "print(\"--- Configuration Complete ---\")\n",
    "print(f\"Feature source directory: {FEATURE_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "# --- 3. Data Loading and Preprocessing ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"--- Step 1: Loading and Preparing Data ---\")\n",
    "\n",
    "# Initialize lists to aggregate data from all files.\n",
    "labels = []\n",
    "feature_vectors = []\n",
    "filenames = []\n",
    "dataset_labels = []\n",
    "inner_labels = []\n",
    "\n",
    "# Loop through the 6 classes (C_0 to C_5).\n",
    "for i in range(6):\n",
    "    hospital_id = f\"C_{i}\"\n",
    "    \n",
    "    # Construct the full path to the feature file.\n",
    "    feature_file_path = os.path.join(FEATURE_DIR, f\"2features_vit_{hospital_id}.pkl\")\n",
    "\n",
    "    # Check if the file exists before trying to open it.\n",
    "    if os.path.exists(feature_file_path):\n",
    "        print(f\"--> Loading features for {hospital_id} from {feature_file_path}...\")\n",
    "        try:\n",
    "            with open(feature_file_path, \"rb\") as f:\n",
    "                # Load the data from the pickle file.\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Validate .pkl file format\n",
    "                if not data or not all(isinstance(item, tuple) and len(item) == 4 for item in data):\n",
    "                    print(f\"    ‚ö†Ô∏è Invalid format in {feature_file_path}. Expected tuples of (full_path, feature, dataset_label, inner_label).\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract the feature vectors, filenames, dataset labels, and inner labels.\n",
    "                class_features = [item[1] for item in data]\n",
    "                class_filenames = [item[0] for item in data]\n",
    "                class_datasets = [item[2] for item in data]\n",
    "                class_inner_labels = [item[3] for item in data]\n",
    "                \n",
    "                # Validate dataset labels\n",
    "                if not all(ds == hospital_id for ds in class_datasets):\n",
    "                    print(f\"    ‚ö†Ô∏è Warning: Some dataset labels in {feature_file_path} do not match {hospital_id}.\")\n",
    "                \n",
    "                # Append to master lists.\n",
    "                feature_vectors.extend(class_features)\n",
    "                filenames.extend(class_filenames)\n",
    "                dataset_labels.extend(class_datasets)\n",
    "                inner_labels.extend(class_inner_labels)\n",
    "                labels.extend([hospital_id] * len(class_features))\n",
    "                \n",
    "                print(f\"    ‚úÖ Loaded {len(class_features)} feature vectors for {hospital_id}.\")\n",
    "                # Report any 'Unknown' inner labels\n",
    "                unknown_count = sum(1 for il in class_inner_labels if il == 'Unknown')\n",
    "                if unknown_count > 0:\n",
    "                    print(f\"    ‚ö†Ô∏è Found {unknown_count} 'Unknown' inner labels in {hospital_id}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è Error loading {feature_file_path}: {e}. Skipping.\")\n",
    "    else:\n",
    "        print(f\"    ‚ö†Ô∏è File not found for {hospital_id} at {feature_file_path}. Skipping.\")\n",
    "\n",
    "# Convert to NumPy arrays with float16 to reduce memory usage\n",
    "if not feature_vectors:\n",
    "    print(\"\\nError: No feature files were found. Exiting script.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    feature_vectors = np.array(feature_vectors, dtype=np.float16)\n",
    "    labels = np.array(labels)\n",
    "    filenames = np.array(filenames)\n",
    "    dataset_labels = np.array(dataset_labels)\n",
    "    inner_labels = np.array(inner_labels)\n",
    "except MemoryError as e:\n",
    "    print(f\"\\nError: MemoryError during array conversion: {e}\")\n",
    "    print(\"Consider running on a system with 32+ GB RAM or a cloud instance (e.g., AWS EC2 r5.2xlarge with 64 GB RAM).\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nSuccessfully combined all features.\")\n",
    "print(f\"Shape of the combined data matrix: {feature_vectors.shape}\")\n",
    "\n",
    "# --- 4. Data Standardization ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 2: Standardizing Data ---\")\n",
    "scaler = StandardScaler()\n",
    "try:\n",
    "    standardized_data = scaler.fit_transform(feature_vectors)\n",
    "except MemoryError as e:\n",
    "    print(f\"\\nError: MemoryError during standardization: {e}\")\n",
    "    print(\"Consider running on a system with 32+ GB RAM or a cloud instance.\")\n",
    "    exit()\n",
    "print(\"‚úÖ Full data has been standardized (zero mean, unit variance).\\n\")\n",
    "\n",
    "# --- 5. t-SNE Analysis on Full Data ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"--- Step 3: Applying t-SNE to Full Dataset ---\")\n",
    "\n",
    "# Adjust perplexity based on dataset size (lower to reduce memory)\n",
    "n_samples = len(feature_vectors)\n",
    "perplexity = min(10, max(5, n_samples // 3))  # Lower perplexity to reduce memory\n",
    "print(f\"Using perplexity={perplexity} for full t-SNE (adjusted for {n_samples} samples).\")\n",
    "\n",
    "# Initialize t-SNE with 2 components\n",
    "try:\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, init='pca', n_jobs=-1)\n",
    "    tsne_result = tsne.fit_transform(standardized_data)\n",
    "except MemoryError as e:\n",
    "    print(f\"\\nError: MemoryError during t-SNE computation: {e}\")\n",
    "    print(f\"t-SNE on {n_samples} samples requires significant memory. Consider:\")\n",
    "    print(\"- Running on a system with 32+ GB RAM or a cloud instance (e.g., AWS EC2 r5.2xlarge).\")\n",
    "    print(\"- Using UMAP instead (contact for alternative script).\")\n",
    "    exit()\n",
    "\n",
    "print(\"‚úÖ t-SNE fitting and transformation complete.\")\n",
    "print(f\"Shape of data after t-SNE: {tsne_result.shape}\")\n",
    "print(f\"KL divergence (cost function): {tsne.kl_divergence_:.4f}\")\n",
    "\n",
    "# --- 6. Subsampling for Visualization ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 4: Subsampling for Visualization ---\")\n",
    "sub_indices = []\n",
    "num_classes = 5  # Updated to 6 classes (C_0 to C_4)\n",
    "subsample_size_per_class = max(1, SUBSAMPLE_SIZE // num_classes)\n",
    "unique_labels = sorted(set(labels))\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = np.where(labels == label)[0]\n",
    "    n_label = len(label_indices)\n",
    "    n_sub_label = min(n_label, max(subsample_size_per_class, int(n_label * SUBSAMPLE_FRACTION)))\n",
    "    if n_label > 0:\n",
    "        sub_label_idx = np.random.choice(label_indices, size=n_sub_label, replace=False)\n",
    "        sub_indices.extend(sub_label_idx)\n",
    "\n",
    "sub_indices = np.array(sub_indices)\n",
    "sub_tsne_result = tsne_result[sub_indices]\n",
    "sub_labels = labels[sub_indices]\n",
    "sub_filenames = filenames[sub_indices]\n",
    "print(f\"    ‚úÖ Subsampled {len(sub_indices)} points for visualization.\")\n",
    "print(f\"    Subsampled t-SNE shape: {sub_tsne_result.shape}\")\n",
    "\n",
    "# --- 7. Generate Excel File with Full t-SNE Results ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 5: Generating Excel File with Full t-SNE Results ---\")\n",
    "\n",
    "# Create a DataFrame for all samples' t-SNE coordinates and metadata\n",
    "excel_data_full = {\n",
    "    'Filename': [],\n",
    "    'Path': [],\n",
    "    'tSNE_X': [],\n",
    "    'tSNE_Y': [],\n",
    "    'Dataset': [],\n",
    "    'Inner_Label': []\n",
    "}\n",
    "\n",
    "for idx in range(len(filenames)):\n",
    "    excel_data_full['Filename'].append(os.path.basename(filenames[idx]))\n",
    "    excel_data_full['Path'].append(filenames[idx])\n",
    "    excel_data_full['tSNE_X'].append(tsne_result[idx, 0])\n",
    "    excel_data_full['tSNE_Y'].append(tsne_result[idx, 1])\n",
    "    excel_data_full['Dataset'].append(dataset_labels[idx])\n",
    "    excel_data_full['Inner_Label'].append(inner_labels[idx])\n",
    "\n",
    "# Convert to DataFrame and save to Excel\n",
    "try:\n",
    "    excel_df_full = pd.DataFrame(excel_data_full)\n",
    "    excel_full_output_path = os.path.join(OUTPUT_DIR, 'all_data_with_tsne_C0_to_C5.xlsx')\n",
    "    excel_df_full.to_excel(excel_full_output_path, index=False, engine='openpyxl')\n",
    "    print(f\"‚úÖ Excel file with full t-SNE results saved to: {excel_full_output_path}\")\n",
    "except MemoryError as e:\n",
    "    print(f\"\\nError: MemoryError during Excel generation: {e}\")\n",
    "    print(\"Consider running on a system with 32+ GB RAM or a cloud instance.\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. Visualization ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 6: Visualizing t-SNE Results ---\")\n",
    "\n",
    "# Scatter plot of t-SNE results (subsampled points)\n",
    "try:\n",
    "    plt.style.use('ggplot')\n",
    "except OSError:\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    plt.rcParams['grid.linewidth'] = 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Plot subsampled t-SNE points\n",
    "palette = sns.color_palette(\"deep\", n_colors=len(unique_labels))\n",
    "color_map = dict(zip(unique_labels, palette))\n",
    "for label, color in color_map.items():\n",
    "    sub_label_mask = (sub_labels == label)\n",
    "    ax.scatter(\n",
    "        sub_tsne_result[sub_label_mask, 0],\n",
    "        sub_tsne_result[sub_label_mask, 1],\n",
    "        label=label,\n",
    "        color=color,\n",
    "        alpha=0.6,\n",
    "        s=15\n",
    "    )\n",
    "\n",
    "ax.set_title('2D t-SNE of ViT Feature Embeddings by Class (Subsampled, C_0 to C_5)', fontsize=18, fontweight='bold')\n",
    "ax.set_xlabel('tSNE_X', fontsize=12)\n",
    "ax.set_ylabel('tSNE_Y', fontsize=12)\n",
    "ax.legend(title='Class ID', fontsize=10)\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "tsne_plot_path = os.path.join(OUTPUT_DIR, 'tsne_visualization.png')\n",
    "plt.savefig(tsne_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ t-SNE visualization saved to: {tsne_plot_path}\")\n",
    "\n",
    "# Close all figures to free memory\n",
    "plt.close('all')\n",
    "\n",
    "# --- 9. Save Processed Data for Future Use ---\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Step 7: Saving t-SNE Results and Labels ---\")\n",
    "\n",
    "tsne_output_path = os.path.join(OUTPUT_DIR, 'tsne_result_full.npy')\n",
    "np.save(tsne_output_path, tsne_result)\n",
    "print(f\"‚úÖ Full t-SNE transformed data saved to: {tsne_output_path}\")\n",
    "\n",
    "labels_output_path = os.path.join(OUTPUT_DIR, 'labels_full.npy')\n",
    "np.save(labels_output_path, labels)\n",
    "print(f\"‚úÖ Full labels saved to: {labels_output_path}\")\n",
    "\n",
    "print(\"\\n--- Script Finished Successfully ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAMLET C2 OOD EVALUATION CONFIG WITH OPTUNA BEST PARAMETERS\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. IMPORTS & SETUP\n",
    "# ==============================================================================\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from multiprocessing import freeze_support\n",
    "from typing import Union, Dict, List, Tuple\n",
    "from scipy.spatial.distance import cdist\n",
    "import shutil\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, default_collate\n",
    "from transformers import ViTForImageClassification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "try:\n",
    "    from torch.cuda.amp import autocast\n",
    "except ImportError:\n",
    "    from torch.cpu.amp import autocast\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CONFIGURATION - USING OPTUNA'S BEST PARAMETERS (TRIAL 21)\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"A centralized configuration class for the C_2 as OOD experiment using best parameters.\"\"\"\n",
    "    # --- Path Configuration ---\n",
    "    # Experts: C0, C1, C3, C4\n",
    "    MODEL_CHECKPOINTS: List[str] = [\n",
    "        r\"d:/new_patches/new_patches/C_0/model/checkpoint_epoch9_valloss0.0343.pth\",\n",
    "        r\"d:/new_patches/new_patches/C_1/model/checkpoint_epoch10_valloss0.0404.pth\", \n",
    "        r\"d:/new_patches/new_patches/C_3/model/checkpoint_epoch9_valloss0.0330_20250429_174446.pth\",\n",
    "        r\"D:/new_patches/new_patches/C_4/model/checkpoint_epoch7_valloss0.0344_20250429_133142.pth\" \n",
    "    ]\n",
    "    \n",
    "    # --- Experiment Configuration ---\n",
    "    TEST_SET_PATH: str = r\"D:\\new_patches\\new_patches\\C_2\"\n",
    "    \n",
    "    # --- OPTUNA BEST PARAMETERS (TRIAL 21 - Accuracy: 93.58%) ---\n",
    "    NUM_REPRESENTATIVE_SAMPLES: int = 29\n",
    "    NUM_CLOSEST_SAMPLES_PER_REP: int = 2300\n",
    "    \n",
    "    XGB_N_ESTIMATORS: int = 75\n",
    "    XGB_MAX_DEPTH: int = 2\n",
    "    XGB_LEARNING_RATE: float = 0.28819589755209746\n",
    "\n",
    "    MLP_HIDDEN_LAYERS: List[int] = [20, 4] # MLP_LAYER_1_SIZE: 20, MLP_LAYER_2_SIZE: 4\n",
    "    MLP_EPOCHS: int = 13\n",
    "    MLP_LR: float = 0.0012246613206706332\n",
    "\n",
    "    ATTENTION_EPOCHS: int = 23\n",
    "    ATTENTION_LR: float = 0.003003575085410412\n",
    "    # --- END OPTUNA PARAMETERS ---\n",
    "    \n",
    "    # --- Data Source Configuration ---\n",
    "    FEATURE_SPACE_EXCEL_PATH: str = r'D:\\.kaggle\\outputs_newRR5_vit_tsne_full09212025\\all_data_with_tsne.xlsx' \n",
    "    SOURCE_DATASET_NAMES: List[str] = [\"C_0\", \"C_1\", \"C_3\", \"C_4\"]\n",
    "    \n",
    "    # --- Visualization Configuration ---\n",
    "    # **ENABLED: Setting to True for final report generation.**\n",
    "    CREATE_VISUALIZATIONS: bool = True\n",
    "    VIZ_OTHER_SAMPLES_COUNT: int = 5000 \n",
    "    \n",
    "    # --- Output & Temporary Directories ---\n",
    "    # **NEW OUTPUT FOLDER for FINAL REPORT**\n",
    "    OUTPUT_DIR_BASE: str = r\"D:/.kaggle/C2_OOD_Evaluation_FINAL_REPORT\" \n",
    "    \n",
    "    # --- Model & Evaluation Parameters ---\n",
    "    BATCH_SIZE: int = 128 \n",
    "    NUM_WORKERS: int = 0\n",
    "    NUM_LABELS: int = 2\n",
    "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    RANDOM_STATE: int = 42\n",
    "\n",
    "    # --- Expert Model Names for Logic ---\n",
    "    EXPERT_NAMES: List[str] = [\"C_0\", \"C_1\", \"C_3\", \"C_4\"]\n",
    "    TARGET_NAME: str = \"C_2\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. UTILITY FUNCTIONS & META-MODEL CLASSES\n",
    "# ==============================================================================\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Sets the random seed for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class AttentionGatingNetwork(nn.Module):\n",
    "    def __init__(self, num_models: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(num_models * num_classes, num_models)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.softmax(self.layer(x))\n",
    "\n",
    "class MLPMetaModel(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_layers: List[int], output_size: int):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(current_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_size = hidden_size\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "class ImageListDataset(Dataset):\n",
    "    \"\"\"A custom dataset to load a list of images and their labels from a DataFrame.\"\"\"\n",
    "    def __init__(self, dataframe: pd.DataFrame, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image = robust_pil_loader(row['Path'])\n",
    "        label_str = str(row['Inner_Label'])\n",
    "        label_int = 1 if 'L_1' in label_str else 0\n",
    "        label = torch.tensor(label_int, dtype=torch.long)\n",
    "        \n",
    "        if image and self.transform:\n",
    "             image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def print_section_header(title: str):\n",
    "    print(\"\\n\" + \"=\" * 80); print(f\"| {title.upper():^76} |\"); print(\"=\" * 80)\n",
    "\n",
    "def robust_pil_loader(path: str) -> Union[Image.Image, None]:\n",
    "    try:\n",
    "        with open(path, \"rb\") as f: return Image.open(f).convert(\"RGB\")\n",
    "    except (UnidentifiedImageError, OSError, FileNotFoundError): return None\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def collate_fn_skip_corrupted(batch: list) -> Tuple:\n",
    "    \"\"\"\n",
    "    Custom collate function that filters out samples with corrupted images (None).\n",
    "    \"\"\"\n",
    "    valid_batch = [item for item in batch if item[0] is not None]\n",
    "    if not valid_batch:\n",
    "        return (None, None)\n",
    "    return default_collate(valid_batch)\n",
    "\n",
    "# **COORDINATE DETECTION (Crucial for stability)**\n",
    "def get_coordinate_columns(df: pd.DataFrame) -> Tuple[List[str], str, bool]:\n",
    "    \"\"\"Identifies the correct coordinate columns (tSNE or UMAP) regardless of case.\"\"\"\n",
    "    \n",
    "    available_cols = [col.upper() for col in df.columns]\n",
    "    \n",
    "    if 'TSNE_X' in available_cols and 'TSNE_Y' in available_cols:\n",
    "        x_col = df.columns[available_cols.index('TSNE_X')]\n",
    "        y_col = df.columns[available_cols.index('TSNE_Y')]\n",
    "        return [x_col, y_col], \"t-SNE\", True\n",
    "    elif 'UMAP_X' in available_cols and 'UMAP_Y' in available_cols:\n",
    "        x_col = df.columns[available_cols.index('UMAP_X')]\n",
    "        y_col = df.columns[available_cols.index('UMAP_Y')]\n",
    "        return [x_col, y_col], \"UMAP\", True\n",
    "    else:\n",
    "        # Returns default columns and False flag if necessary columns are missing.\n",
    "        print(\"‚ùå FATAL: Could not find UMAP or t-SNE columns in the Excel file.\")\n",
    "        return ['tSNE_X', 'tSNE_Y'], \"t-SNE (Missing)\", False\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. CORE COMPUTATIONAL, VISUALIZATION & REPORTING FUNCTIONS\n",
    "# ==============================================================================\n",
    "def find_representative_samples(test_set_df: pd.DataFrame, config: Config) -> Tuple[List[str], pd.DataFrame]:\n",
    "    \"\"\"Uses K-Means clustering on the provided test set to find archetypal samples.\"\"\"\n",
    "    \n",
    "    num_representatives = config.NUM_REPRESENTATIVE_SAMPLES\n",
    "    coord_cols, coord_name, found = get_coordinate_columns(test_set_df)\n",
    "\n",
    "    if not found:\n",
    "        return [], pd.DataFrame()\n",
    "        \n",
    "    print(f\"  > Clustering {len(test_set_df)} total samples into {num_representatives} groups based on {coord_name} coordinates alone.\")\n",
    "    \n",
    "    representative_paths = []\n",
    "    \n",
    "    if not test_set_df.empty and len(test_set_df) >= num_representatives:\n",
    "        coords = test_set_df[coord_cols].values\n",
    "        kmeans = KMeans(n_clusters=num_representatives, random_state=config.RANDOM_STATE, n_init=10).fit(coords)\n",
    "        \n",
    "        for centroid in kmeans.cluster_centers_:\n",
    "            distances = cdist(centroid.reshape(1, -1), coords, 'euclidean').flatten()\n",
    "            closest_idx = np.argmin(distances)\n",
    "            representative_paths.append(test_set_df.iloc[closest_idx]['Path'])\n",
    "    \n",
    "    representative_df = test_set_df[test_set_df['Path'].isin(representative_paths)]\n",
    "    return representative_paths, representative_df\n",
    "\n",
    "def find_closest_samples(target_sample_path: str, feature_space_df: pd.DataFrame, config: Config) -> pd.DataFrame:\n",
    "    \"\"\"Identifies the N closest source samples to a single target sample.\"\"\"\n",
    "    \n",
    "    num_closest = config.NUM_CLOSEST_SAMPLES_PER_REP\n",
    "    coord_cols, _, found = get_coordinate_columns(feature_space_df)\n",
    "    if not found:\n",
    "        return None\n",
    "        \n",
    "    target_filename = Path(target_sample_path).name\n",
    "    target_row = feature_space_df[feature_space_df['Filename'] == target_filename]\n",
    "    if target_row.empty: return None\n",
    "        \n",
    "    target_vector = target_row[coord_cols].values\n",
    "    source_df = feature_space_df[feature_space_df['Dataset'].isin(config.SOURCE_DATASET_NAMES)].copy()\n",
    "    if source_df.empty: return None\n",
    "\n",
    "    source_vectors = source_df[coord_cols].values\n",
    "    distances = cdist(target_vector, source_vectors, 'euclidean').flatten()\n",
    "    \n",
    "    source_df['Distance_to_Target'] = distances\n",
    "    closest_df = source_df.nsmallest(num_closest, 'Distance_to_Target')\n",
    "    return closest_df\n",
    "\n",
    "def load_models(config: Config) -> List[torch.nn.Module]:\n",
    "    print_section_header(\"Loading Base Models\")\n",
    "    models = []\n",
    "    for idx, path in enumerate(config.MODEL_CHECKPOINTS):\n",
    "        try:\n",
    "            model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=config.NUM_LABELS, ignore_mismatched_sizes=True)\n",
    "            checkpoint = torch.load(path, map_location=config.DEVICE, weights_only=True)\n",
    "            model.load_state_dict(checkpoint.get('model_state_dict', checkpoint))\n",
    "            model.to(config.DEVICE).eval()\n",
    "            models.append(model)\n",
    "            print(f\"   > Model {config.EXPERT_NAMES[idx]} loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå FATAL: Could not load model from {path}: {e}. Exiting.\")\n",
    "            exit()\n",
    "    return models\n",
    "\n",
    "def get_predictions(models: List[torch.nn.Module], loader: DataLoader, config: Config, desc: str, leave_progress=True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Gets predictions for a given dataloader.\"\"\"\n",
    "    num_models = len(models)\n",
    "    all_probs, true_labels = [[] for _ in range(num_models)], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=desc, leave=leave_progress):\n",
    "            if images is None: continue\n",
    "            images = images.to(config.DEVICE)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            # Fixed deprecated call from older code versions\n",
    "            with torch.amp.autocast('cuda', enabled=(config.DEVICE.type == 'cuda')): \n",
    "                for i, model in enumerate(models):\n",
    "                    logits = model(images).logits\n",
    "                    all_probs[i].extend(torch.softmax(logits, dim=1).cpu().numpy())\n",
    "    return np.array(all_probs), np.array(true_labels)\n",
    "\n",
    "def calculate_proximity_weights(dataset_counts: pd.Series, config: Config) -> np.ndarray:\n",
    "    \"\"\"Calculates model weights based on their dataset's proximity to the target.\"\"\"\n",
    "    total_samples = dataset_counts.sum()\n",
    "    weights = [dataset_counts.get(name, 0) / total_samples for name in config.EXPERT_NAMES]\n",
    "    return np.array(weights)\n",
    "\n",
    "def train_all_stacking_models(meta_features_np: np.ndarray, meta_train_labels: np.ndarray, config: Config, models: List[torch.nn.Module]) -> Dict[str, any]:\n",
    "    \n",
    "    trained_meta_models = {}\n",
    "    lr_model = LogisticRegression(random_state=config.RANDOM_STATE, max_iter=1000).fit(meta_features_np, meta_train_labels)\n",
    "    trained_meta_models[\"Stacking_LR\"] = lr_model\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=config.XGB_N_ESTIMATORS, max_depth=config.XGB_MAX_DEPTH,\n",
    "        learning_rate=config.XGB_LEARNING_RATE, random_state=config.RANDOM_STATE,\n",
    "        eval_metric='logloss' \n",
    "    ).fit(meta_features_np, meta_train_labels)\n",
    "    trained_meta_models[\"Stacking_XGB\"] = xgb_model\n",
    "\n",
    "    mlp_model = MLPMetaModel(\n",
    "        input_size=len(models) * config.NUM_LABELS, hidden_layers=config.MLP_HIDDEN_LAYERS,\n",
    "        output_size=config.NUM_LABELS\n",
    "    ).to(config.DEVICE)\n",
    "    \n",
    "    mlp_dataset = TensorDataset(torch.from_numpy(meta_features_np).float(), torch.from_numpy(meta_train_labels).long())\n",
    "    mlp_loader = DataLoader(mlp_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(mlp_model.parameters(), lr=config.MLP_LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    mlp_model.train()\n",
    "    for epoch in tqdm(range(config.MLP_EPOCHS), desc=\"   => Training MLP\", leave=False):\n",
    "        for x_batch, y_batch in mlp_loader:\n",
    "            x_batch, y_batch = x_batch.to(config.DEVICE), y_batch.to(config.DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = mlp_model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    mlp_model.eval()\n",
    "    trained_meta_models[\"Stacking_MLP\"] = mlp_model\n",
    "    return trained_meta_models\n",
    "\n",
    "def train_attention_network(train_probs: np.ndarray, train_labels: np.ndarray, config: Config, base_models: List[torch.nn.Module]) -> AttentionGatingNetwork:\n",
    "    \n",
    "    train_probs_t = torch.from_numpy(train_probs.swapaxes(0, 1)).to(config.DEVICE)\n",
    "    meta_features = train_probs_t.reshape(train_probs_t.shape[0], -1)\n",
    "    train_labels_t = torch.from_numpy(train_labels).long().to(config.DEVICE)\n",
    "    \n",
    "    attention_train_dataset = TensorDataset(meta_features.float(), train_probs_t.float(), train_labels_t)\n",
    "    attention_loader = DataLoader(attention_train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    attention_net = AttentionGatingNetwork(len(base_models), config.NUM_LABELS).to(config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(attention_net.parameters(), lr=config.ATTENTION_LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    attention_net.train()\n",
    "    for epoch in tqdm(range(config.ATTENTION_EPOCHS), desc=\"   => Training Attention Net\", leave=False):\n",
    "        for x_batch, probs_batch, y_batch in attention_loader:\n",
    "            optimizer.zero_grad()\n",
    "            attention_weights = attention_net(x_batch)\n",
    "            weighted_probs = probs_batch * attention_weights.unsqueeze(-1)\n",
    "            final_probs = torch.sum(weighted_probs, dim=1)\n",
    "            loss = criterion(final_probs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    attention_net.eval()\n",
    "    return attention_net\n",
    "\n",
    "def apply_ensembles(all_probs: np.ndarray, proximity_weights: np.ndarray, attention_net: AttentionGatingNetwork, config: Config) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Applies all specialized and standard ensemble methods.\"\"\"\n",
    "    all_preds = np.argmax(all_probs, axis=2)\n",
    "    ensembles = {\"Majority Vote\": np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_preds)}\n",
    "\n",
    "    if proximity_weights is not None and proximity_weights.any():\n",
    "        ensembles[\"Proximity_Weighted (Soft)\"] = np.argmax(np.einsum('j,ijk->ik', proximity_weights, all_probs.transpose(1, 0, 2)), axis=1)\n",
    "\n",
    "    if attention_net:\n",
    "        test_probs_t = torch.from_numpy(all_probs.swapaxes(0, 1)).to(config.DEVICE)\n",
    "        meta_features_test = test_probs_t.reshape(test_probs_t.shape[0], -1)\n",
    "        with torch.no_grad():\n",
    "            attention_weights = attention_net(meta_features_test.float())\n",
    "        weighted_probs = test_probs_t.cpu().numpy() * attention_weights.cpu().numpy()[:, :, np.newaxis]\n",
    "        final_probs = np.sum(weighted_probs, axis=1)\n",
    "        ensembles[\"Attention_Ensemble (Specialized)\"] = np.argmax(final_probs, axis=1)\n",
    "\n",
    "    return ensembles\n",
    "\n",
    "def create_detailed_visualizations(feature_space_df: pd.DataFrame, specific_test_df: pd.DataFrame, representative_paths: List[str], representative_df: pd.DataFrame, config: Config):\n",
    "    \"\"\"Generates a series of plots to visualize the feature space.\"\"\"\n",
    "    print_section_header(\"Generating Visualizations\")\n",
    "    viz_dir = Path(config.OUTPUT_DIR_BASE) / \"visualizations\"\n",
    "    viz_dir.mkdir(exist_ok=True, parents=True)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    coord_cols, coord_name, _ = get_coordinate_columns(feature_space_df)\n",
    "    coord_x, coord_y = coord_cols[0], coord_cols[1]\n",
    "\n",
    "    # --- Plot 1: Overall Feature Space of All Datasets ---\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    sns.scatterplot(x=coord_x, y=coord_y, hue='Dataset', data=feature_space_df, palette='tab10', alpha=0.6, s=15, legend='full')\n",
    "    plt.title(f'Global {coord_name} Feature Space of All Datasets', fontsize=20, weight='bold')\n",
    "    plt.xlabel(f'{coord_name} Dimension 1', fontsize=12); plt.ylabel(f'{coord_name} Dimension 2', fontsize=12)\n",
    "    plt.legend(title='Dataset', loc='best', markerscale=2)\n",
    "    plt.savefig(viz_dir / \"01_global_feature_space.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  > Saved plot 1: Global Feature Space\")\n",
    "\n",
    "    # --- Plot 3: OOD Test Set with Class Labels and Representative Anchors ---\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    sns.scatterplot(x=coord_x, y=coord_y, hue='Inner_Label', data=specific_test_df, palette={'L_0': 'royalblue', 'L_1': 'crimson'}, alpha=0.5, s=20)\n",
    "    \n",
    "    if not representative_df.empty:\n",
    "        plt.scatter(representative_df[coord_x], representative_df[coord_y], marker='*', s=400, c='gold', edgecolor='black', linewidth=1, label='Representative Anchors')\n",
    "    \n",
    "        path_to_r_number = {path: f'R{i+1}' for i, path in enumerate(representative_paths)}\n",
    "        for i, row in representative_df.iterrows():\n",
    "            try:\n",
    "                anchor_index = representative_paths.index(row['Path']) + 1\n",
    "                plt.text(row[coord_x] + 0.5, row[coord_y] + 0.5, f'R{anchor_index}', fontsize=12, weight='bold', color='black')\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "\n",
    "    plt.title(f'Distribution of {config.TARGET_NAME} with {len(representative_paths)} Anchors', fontsize=18, weight='bold')\n",
    "    plt.xlabel(f'{coord_name} Dimension 1'); plt.ylabel(f'{coord_name} Dimension 2')\n",
    "    plt.legend(title='Class')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.savefig(viz_dir / \"03_test_set_with_anchors_kmeans.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  > Saved plot 3: OOD Test Set with Anchors (KMeans)\")\n",
    "\n",
    "    # --- Plots 4-N: Individual Anchor Neighborhoods ---\n",
    "    source_df = feature_space_df[feature_space_df['Dataset'].isin(config.SOURCE_DATASET_NAMES)].copy()\n",
    "    path_to_r_number = {path: f'R{i+1}' for i, path in enumerate(representative_paths)}\n",
    "    \n",
    "    for path in tqdm(representative_paths, desc=\"  > Generating Anchor Neighborhood Plots\"):\n",
    "        closest_df = find_closest_samples(path, feature_space_df, config)\n",
    "        if closest_df is None: continue\n",
    "        \n",
    "        anchor_row = feature_space_df[feature_space_df['Path'] == path]\n",
    "        anchor_name = path_to_r_number.get(path, 'Unknown')\n",
    "        \n",
    "        plt.figure(figsize=(16, 12))\n",
    "        other_source_df = source_df.drop(closest_df.index).sample(n=min(config.VIZ_OTHER_SAMPLES_COUNT, len(source_df) - len(closest_df)), random_state=config.RANDOM_STATE)\n",
    "        sns.scatterplot(x=coord_x, y=coord_y, data=other_source_df, color='gainsboro', alpha=0.5, label='Other Source Samples', s=15)\n",
    "        \n",
    "        sns.scatterplot(x=coord_x, y=coord_y, hue='Dataset', data=closest_df, palette='viridis', alpha=0.9, s=50, legend='full')\n",
    "\n",
    "        plt.scatter(anchor_row[coord_x], anchor_row[coord_y], marker='*', s=700, c='red', edgecolor='black', linewidth=1.5, label=f'Anchor {anchor_name}')\n",
    "        \n",
    "        plt.title(f'KNN Neighborhood for Anchor {anchor_name}: {Path(path).name} (N={config.NUM_CLOSEST_SAMPLES_PER_REP})', fontsize=16, weight='bold')\n",
    "        plt.xlabel(f'{coord_name} Dimension 1'); plt.ylabel(f'{coord_name} Dimension 2')\n",
    "        plt.legend(title='Dataset')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.savefig(viz_dir / f\"04_{anchor_name}_anchor_{Path(path).stem}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def compute_full_metrics(true_labels: np.ndarray, preds: np.ndarray) -> Dict[str, any]:\n",
    "    \"\"\"Computes a detailed dictionary of classification metrics.\"\"\"\n",
    "    cm = confusion_matrix(true_labels, preds, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0,0,0,0)\n",
    "    \n",
    "    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0.0\n",
    "    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0.0\n",
    "    \n",
    "    class0_mask, class1_mask = true_labels == 0, true_labels == 1\n",
    "    \n",
    "    return {\n",
    "        \"acc\": 100 * np.sum(preds == true_labels) / len(true_labels) if len(true_labels) > 0 else 0.0,\n",
    "        \"class0_acc\": 100 * np.sum(preds[class0_mask] == true_labels[class0_mask]) / class0_mask.sum() if class0_mask.sum() > 0 else 0.0,\n",
    "        \"class1_acc\": 100 * np.sum(preds[class1_mask] == true_labels[class1_mask]) / class1_mask.sum() if class1_mask.sum() > 0 else 0.0,\n",
    "        \"precision\": [precision_0, precision_1], \"recall\": [recall_0, recall_1], \n",
    "        \"f1\": [f1_0, f1_1], \"correct\": int(np.sum(preds == true_labels)), \"total\": len(true_labels)\n",
    "    }\n",
    "\n",
    "def generate_final_report(all_predictions: Dict[str, np.ndarray], true_labels: np.ndarray, class_names: List[str], config: Config):\n",
    "    \"\"\"Generates a detailed summary report and saves it as an image.\"\"\"\n",
    "    print_section_header(\"Master Summary Report\")\n",
    "    \n",
    "    summary_data = []\n",
    "    method_order = sorted(all_predictions.keys())\n",
    "\n",
    "    for name in method_order:\n",
    "        metrics = compute_full_metrics(true_labels, all_predictions[name])\n",
    "        summary_data.append({\n",
    "            \"Method\": name, \n",
    "            \"Acc (%)\": metrics['acc'], # Store as number for sorting\n",
    "            f\"{class_names[0]} Acc (%)\": f\"{metrics['class0_acc']:.2f}\", \n",
    "            f\"{class_names[1]} Acc (%)\": f\"{metrics['class1_acc']:.2f}\",\n",
    "            \"Prec C0\": f\"{metrics['precision'][0]:.2f}\", \"Prec C1\": f\"{metrics['precision'][1]:.2f}\",\n",
    "            \"Rec C0\": f\"{metrics['recall'][0]:.2f}\", \"Rec C1\": f\"{metrics['recall'][1]:.2f}\",\n",
    "            \"F1 C0\": f\"{metrics['f1'][0]:.2f}\", \"F1 C1\": f\"{metrics['f1'][1]:.2f}\",\n",
    "            \"Correct/Total\": f\"{metrics['correct']}/{metrics['total']}\"\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    # Sort the DataFrame by Accuracy in descending order\n",
    "    summary_df = summary_df.sort_values(by='Acc (%)', ascending=False).reset_index(drop=True)\n",
    "    # Format the accuracy column back to a string with 2 decimal places for display\n",
    "    summary_df['Acc (%)'] = summary_df['Acc (%)'].map('{:.2f}'.format)\n",
    "\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, (len(summary_df) * 0.4 + 1.5)))\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.8)\n",
    "    plt.title(f\"Evaluation Summary for {config.TARGET_NAME} (Optimized - Acc: {summary_df.iloc[0]['Acc (%)']}%)\", fontsize=16, y=1.05)\n",
    "    summary_image_path = Path(config.OUTPUT_DIR_BASE) / \"final_evaluation_summary.png\"\n",
    "    plt.savefig(summary_image_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"\\n‚úÖ Detailed summary table saved as an image to: {summary_image_path}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. MAIN EXECUTION SCRIPT\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the entire evaluation pipeline.\"\"\"\n",
    "    config = Config()\n",
    "    Path(config.OUTPUT_DIR_BASE).mkdir(exist_ok=True, parents=True)\n",
    "    set_seed(config.RANDOM_STATE) \n",
    "    \n",
    "    print_section_header(\"Pipeline Start: Final Report Generation (Optimized Parameters)\")\n",
    "    \n",
    "    # --- 1. Pre-load Static Data (Models and Feature Space) ---\n",
    "    base_models = load_models(config)\n",
    "    try:\n",
    "        feature_space_df = pd.read_excel(config.FEATURE_SPACE_EXCEL_PATH)\n",
    "        feature_space_df['Path'] = feature_space_df['Path'].astype(str)\n",
    "        print(f\"‚úÖ Pre-loaded coordinate data from {config.FEATURE_SPACE_EXCEL_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FATAL ERROR loading coordinate Excel file: {e}\"); exit()\n",
    "        \n",
    "    # --- 2. Define the Specific Test Set ---\n",
    "    test_set_filenames = {p.name for p in Path(config.TEST_SET_PATH).rglob('*') if p.suffix in ['.png', '.jpg', '.jpeg', '.tif']}\n",
    "    specific_test_df = feature_space_df[feature_space_df['Filename'].isin(test_set_filenames)].copy()\n",
    "\n",
    "    if specific_test_df.empty:\n",
    "        print(f\"‚ùå FATAL: No matching filenames found between folder '{config.TEST_SET_PATH}' and the Excel file.\")\n",
    "        exit()\n",
    "    \n",
    "    # --- 3. Run Predictions on Test Set ONCE (Heavy Step) ---\n",
    "    print_section_header(f\"Running Predictions for Test Set ({len(specific_test_df)} images)...\")\n",
    "    full_test_dataset = ImageListDataset(dataframe=specific_test_df, transform=get_transform())\n",
    "    full_test_loader = DataLoader(full_test_dataset, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS, collate_fn=collate_fn_skip_corrupted)\n",
    "    \n",
    "    all_test_probs, true_labels = get_predictions(base_models, full_test_loader, config, \"   => Final Test Set Preds\", leave_progress=True)\n",
    "    print(\"‚úÖ Prediction complete.\")\n",
    "    \n",
    "    # --- 4. Build Aggregate Neighbor Dataset for Training Meta-Models ---\n",
    "    print_section_header(\"Building Aggregate Neighbor Dataset\")\n",
    "    representative_paths, representative_df = find_representative_samples(specific_test_df, config)\n",
    "\n",
    "    all_neighbor_dfs = []\n",
    "    for path in representative_paths:\n",
    "        closest_df = find_closest_samples(path, feature_space_df, config)\n",
    "        if closest_df is not None:\n",
    "            all_neighbor_dfs.append(closest_df)\n",
    "    \n",
    "    if not all_neighbor_dfs:\n",
    "        print(\"‚ùå FATAL: Could not find any neighbors for the representative samples. Halting.\"); exit()\n",
    "\n",
    "    aggregate_neighbors_df = pd.concat(all_neighbor_dfs).drop_duplicates(subset=['Filename']).reset_index(drop=True)\n",
    "    dataset_counts = aggregate_neighbors_df['Dataset'].value_counts()\n",
    "    print(f\"  > Created aggregate training set with {len(aggregate_neighbors_df)} unique neighbors.\")\n",
    "    \n",
    "    # --- 5. Train specialized meta-models ---\n",
    "    print_section_header(\"Training Meta-Models with Optimized Parameters\")\n",
    "    transform = get_transform()\n",
    "    neighbor_dataset = ImageListDataset(dataframe=aggregate_neighbors_df, transform=transform)\n",
    "    neighbor_loader = DataLoader(neighbor_dataset, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS, collate_fn=collate_fn_skip_corrupted)\n",
    "    \n",
    "    meta_train_probs, meta_train_labels = get_predictions(base_models, neighbor_loader, config, \"   => Neighbor Preds\", leave_progress=True)\n",
    "    \n",
    "    meta_features_np = meta_train_probs.swapaxes(0, 1).reshape(meta_train_probs.shape[1], -1)\n",
    "    \n",
    "    trained_meta_models = train_all_stacking_models(meta_features_np, meta_train_labels, config, base_models)\n",
    "    attention_network = train_attention_network(meta_train_probs, meta_train_labels, config, base_models)\n",
    "    proximity_weights = calculate_proximity_weights(dataset_counts, config)\n",
    "\n",
    "    # --- 6. Apply all ensemble methods on the Test Set ---\n",
    "    print_section_header(\"Applying Ensemble Models\")\n",
    "    all_predictions = {f\"Model_{name}\": np.argmax(all_test_probs[i], axis=1) for i, name in enumerate(config.EXPERT_NAMES)}\n",
    "    all_predictions.update(apply_ensembles(all_test_probs, proximity_weights, attention_network, config))\n",
    "\n",
    "    # --- Apply the specialized stacking models ---\n",
    "    if trained_meta_models:\n",
    "        meta_features_test = all_test_probs.swapaxes(0, 1).reshape(all_test_probs.shape[1], -1)\n",
    "        for name, meta_model in trained_meta_models.items():\n",
    "            if isinstance(meta_model, (LogisticRegression, XGBClassifier)):\n",
    "                all_predictions[name] = meta_model.predict(meta_features_test)\n",
    "            elif isinstance(meta_model, nn.Module):\n",
    "                with torch.no_grad():\n",
    "                    meta_features_t = torch.from_numpy(meta_features_test).float().to(config.DEVICE)\n",
    "                    outputs = meta_model(meta_features_t)\n",
    "                    all_predictions[name] = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "    # --- 7. Final Reporting & Saving Results ---\n",
    "    generate_final_report(all_predictions, true_labels, ['L_0', 'L_1'], config)\n",
    "\n",
    "    if config.CREATE_VISUALIZATIONS:\n",
    "        print_section_header(\"Generating Feature Space Visualizations\")\n",
    "        create_detailed_visualizations(feature_space_df, specific_test_df, representative_paths, representative_df, config)\n",
    "\n",
    "    # Save per-image results to Excel\n",
    "    processed_paths_df = specific_test_df.iloc[:len(true_labels)]\n",
    "    summary_df = pd.DataFrame({'ImagePath': processed_paths_df['Path'].tolist(), 'TrueLabel': true_labels})\n",
    "    for method, preds in all_predictions.items():\n",
    "        summary_df[f'{method}_Pred'] = preds\n",
    "    \n",
    "    summary_path = Path(config.OUTPUT_DIR_BASE) / f\"per_image_results_FINAL_REPORT.xlsx\"\n",
    "    summary_df.to_excel(summary_path, index=False)\n",
    "    print(f\"\\n‚úÖ Per-image prediction results saved to: {summary_path}\")\n",
    "\n",
    "    print_section_header(\"PIPELINE FINISHED - REPORT GENERATED\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
